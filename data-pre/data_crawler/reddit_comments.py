# -*- coding: utf-8 -*-
"""
reddit_stage2_posts_and_comments.py
æ ¹æ® post_id åˆ—è¡¨æŠ“å–ï¼šâ‘ å®Œæ•´è¯„è®ºæ ‘ â‘¡å¯¹åº”å¸–å­å…ƒæ•°æ®

ç”¨æ³•ï¼š
    python3 reddit_official_comments.py \
        --ids post_ids.txt \
        --out reddit_stage4_post_comments \
        --sleep 0.3
"""
import os, json, csv, argparse, time
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
import praw
from praw.models import MoreComments

# -------- Reddit Client --------
def load_reddit():
    load_dotenv()
    reddit = praw.Reddit(
        client_id=os.getenv("REDDIT_CLIENT_ID"),
        client_secret=None,                  # read-onlyï¼Œæ— éœ€ secret
        user_agent=os.getenv("REDDIT_USER_AGENT") or "COMP9900/0.1",
        check_for_async=False,
    )
    reddit.read_only = True
    print("âœ… Reddit read-only client ready")
    return reddit

# -------- Helpers --------
def _submission_row(s):
    """æŠŠå¸–å­å¯¹è±¡æ‹æˆä¸€è¡Œ dictï¼ˆç”¨äºpostsæ–‡ä»¶ & åˆå¹¶åˆ°è¯„è®ºé‡Œï¼‰"""
    return {
        "post_id": s.id,
        "post_title": s.title or "",
        "post_selftext": s.selftext or "",
        "post_author": str(s.author) if s.author else "",
        "post_subreddit": str(s.subreddit) if s.subreddit else "",
        "post_score": s.score,
        "post_num_comments": s.num_comments,
        "post_created_utc": datetime.utcfromtimestamp(s.created_utc).isoformat(),
        "post_permalink": f"https://www.reddit.com{s.permalink}",
        "post_url": s.url or "",
        "post_over_18": bool(getattr(s, "over_18", False)),
        "post_spoiler": bool(getattr(s, "spoiler", False)),
        "post_locked": bool(getattr(s, "locked", False)),
    }

def fetch_comments_with_post(submission):
    """è¿”å› (post_row, comments_rows) å…ƒç»„"""
    post_row = _submission_row(submission)

    # å±•å¼€å®Œæ•´è¯„è®ºæ ‘
    submission.comments.replace_more(limit=None)
    comments_rows = []
    for c in submission.comments.list():
        if isinstance(c, MoreComments):
            continue
        comments_rows.append({
            # è¯„è®ºå­—æ®µ
            "post_id": submission.id,
            "comment_id": c.id,
            "parent_id": c.parent_id,
            "author": str(c.author) if c.author else "",
            "body": (c.body or "")[:8000],
            "score": c.score,
            "created_utc": datetime.utcfromtimestamp(c.created_utc).isoformat(),
            "depth": int(getattr(c, "depth", 0)),
            # æ–¹ä¾¿åˆ†æï¼šæŠŠå…³é”®ä¿¡æ¯å¹¶åˆ°æ¯æ¡è¯„è®º
            **{
                k: post_row[k] for k in [
                    "post_title", "post_selftext", "post_author", "post_subreddit",
                    "post_score", "post_num_comments", "post_created_utc",
                    "post_permalink", "post_url"
                ]
            }
        })
    return post_row, comments_rows

# -------- Main --------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--ids", required=True, help="åŒ…å« post_id çš„ txt æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œå¦‚ï¼š1abcde")
    parser.add_argument("--out", default="reddit_stage4_post_comments", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--sleep", type=float, default=0.3, help="æ¯ä¸ªå¸–å­ä¹‹é—´çš„åœé¡¿ç§’æ•°")
    args = parser.parse_args()

    reddit = load_reddit()
    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)

    # è¯»å–å¾…æŠ“ post_id åˆ—è¡¨
    with open(args.ids, "r", encoding="utf-8") as f:
        post_ids = [line.strip() for line in f if line.strip()]

    all_posts = []
    all_comments = []

    for idx, pid in enumerate(post_ids, 1):
        try:
            s = reddit.submission(id=pid)
            post_row, comments_rows = fetch_comments_with_post(s)
            all_posts.append(post_row)
            all_comments.extend(comments_rows)
            print(f"âœ… [{idx}/{len(post_ids)}] {pid}: {len(comments_rows)} comments")
        except Exception as e:
            print(f"âš ï¸  [{idx}/{len(post_ids)}] {pid} failed: {e}")
        time.sleep(args.sleep)

    ts = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    posts_json = out_dir / f"posts_{ts}.json"
    posts_csv  = out_dir / f"posts_{ts}.csv"
    cmts_json  = out_dir / f"comments_{ts}.json"
    cmts_csv   = out_dir / f"comments_{ts}.csv"

    # ä¿å­˜ posts
    with open(posts_json, "w", encoding="utf-8") as f:
        json.dump(all_posts, f, ensure_ascii=False, indent=2)
    if all_posts:
        with open(posts_csv, "w", newline="", encoding="utf-8") as f:
            w = csv.DictWriter(f, fieldnames=list(all_posts[0].keys()))
            w.writeheader()
            w.writerows(all_posts)

    # ä¿å­˜ comments
    with open(cmts_json, "w", encoding="utf-8") as f:
        json.dump(all_comments, f, ensure_ascii=False, indent=2)
    if all_comments:
        with open(cmts_csv, "w", newline="", encoding="utf-8") as f:
            w = csv.DictWriter(f, fieldnames=list(all_comments[0].keys()))
            w.writeheader()
            w.writerows(all_comments)

    print(f"ğŸ’¾ Saved {len(all_posts)} posts â†’ {posts_json}")
    print(f"ğŸ’¾ Saved {len(all_comments)} comments â†’ {cmts_json}")

if __name__ == "__main__":
    main()
